#!/usr/bin/env python3
"""
æ‰¹æ¬¡åŸºæº–æ¸¬è©¦ (Batch Benchmarking)
æ¸¬è©¦å¤šå€‹æ¨¡å‹ä¸¦ç”Ÿæˆæ¯”è¼ƒå ±å‘Š
"""
import json
from benchmark import run_full_benchmark
from datetime import datetime

# å¾ my_ollama_llms.txt æ¨è–¦çš„æ¨¡å‹
RECOMMENDED_MODELS = {
    'reasoning': 'deepseek-r1:32b',
    'coding': 'qwen2.5-coder:latest',
    'vision': 'llama3.2-vision:latest',
    'general': 'llama3.2:latest',
    'embedding': 'nomic-embed-text:v1.5'
}

def run_batch_benchmark():
    """æ‰¹æ¬¡æ¸¬è©¦æ¨è–¦æ¨¡å‹"""
    print("ğŸš€ æ‰¹æ¬¡åŸºæº–æ¸¬è©¦é–‹å§‹\n")
    
    all_results = {}
    
    for category, model in RECOMMENDED_MODELS.items():
        print(f"\n{'='*60}")
        print(f"æ¸¬è©¦é¡åˆ¥: {category} | æ¨¡å‹: {model}")
        print('='*60)
        
        try:
            results = run_full_benchmark(model)
            all_results[model] = results
        except Exception as e:
            print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
    
    # ç”Ÿæˆæ¯”è¼ƒå ±å‘Š
    report_file = f"./output/benchmark_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… æ‰¹æ¬¡æ¸¬è©¦å®Œæˆï¼å ±å‘Š: {report_file}")

if __name__ == "__main__":
    run_batch_benchmark()
