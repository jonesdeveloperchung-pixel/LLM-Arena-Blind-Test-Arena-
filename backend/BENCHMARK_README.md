# ğŸ§ª LLM åŸºæº–æ¸¬è©¦ç³»çµ±

## ğŸ“‹ åŠŸèƒ½æ¦‚è¦½

å¯¦ä½œ Requirement_Specification.md ä¸­å®šç¾©çš„ 5 å¤§èƒ½åŠ›è©•æ¸¬ï¼š

1. **æ¨ç†èƒ½åŠ›** (Reasoning) - é‚è¼¯æ¨ç†ã€å¤šæ­¥é©Ÿå•é¡Œ
2. **ç·¨ç¢¼èƒ½åŠ›** (Coding) - ç¨‹å¼ç”Ÿæˆã€é™¤éŒ¯ã€è¤‡é›œåº¦åˆ†æ
3. **è¦–è¦ºèªè¨€** (Vision-Language) - åœ–åƒç†è§£ã€å¤šæ¨¡æ…‹æŸ¥è©¢
4. **é€šç”¨èªè¨€** (General Language) - æµæš¢åº¦ã€å‰µæ„ã€å°è©±
5. **åµŒå…¥èƒ½åŠ›** (Embedding) - èªç¾©ç›¸ä¼¼åº¦ã€æª¢ç´¢

---

## ğŸš€ å¿«é€Ÿé–‹å§‹

### æ¸¬è©¦å–®ä¸€æ¨¡å‹
```bash
# æ¸¬è©¦é è¨­æ¨¡å‹
python benchmark.py

# æ¸¬è©¦æŒ‡å®šæ¨¡å‹
python benchmark.py llama3.2-vision:latest
```

### æ‰¹æ¬¡æ¸¬è©¦æ¨è–¦æ¨¡å‹
```bash
python benchmark_batch.py
```

æ¨è–¦æ¨¡å‹é…ç½®ï¼š
- æ¨ç†ï¼š`deepseek-r1:32b`
- ç·¨ç¢¼ï¼š`qwen2.5-coder:latest`
- è¦–è¦ºï¼š`llama3.2-vision:latest`
- é€šç”¨ï¼š`llama3.2:latest`
- åµŒå…¥ï¼š`nomic-embed-text:v1.5`

---

## ğŸ“Š è©•åˆ†ç³»çµ±

### Gemini-as-Judge
- ä½¿ç”¨ Gemini 2.0 Flash ä½œç‚ºè©•å¯©
- è©•åˆ†ç¯„åœï¼š1-5 æ˜Ÿ
- æä¾›è©³ç´°è©•å¯©ç†ç”±
- å„é …æŒ‡æ¨™ç´°åˆ†è©•åˆ†

### è©•åˆ†æ¨™æº–
| åˆ†æ•¸ | ç­‰ç´š | èªªæ˜ |
|------|------|------|
| 5 | å„ªç§€ | å®Œç¾å›æ‡‰ï¼Œè¶…è¶Šé æœŸ |
| 4 | è‰¯å¥½ | æ­£ç¢ºä¸”å®Œæ•´ |
| 3 | ä¸­ç­‰ | åŸºæœ¬æ­£ç¢ºä½†æœ‰æ”¹é€²ç©ºé–“ |
| 2 | ä¸ä½³ | éƒ¨åˆ†éŒ¯èª¤æˆ–ä¸å®Œæ•´ |
| 1 | å¤±æ•— | åš´é‡éŒ¯èª¤æˆ–ç„¡æ³•å›æ‡‰ |

---

## ğŸ“ˆ è¼¸å‡ºæ ¼å¼

### å–®ä¸€æ¸¬è©¦çµæœ
```json
{
  "model": "llama3.2:latest",
  "category": "reasoning",
  "score": 4,
  "reasoning": "æ¨ç†æ­¥é©Ÿæ¸…æ™°...",
  "breakdown": {
    "accuracy": 4,
    "step_clarity": 5,
    "consistency": 4
  }
}
```

### æ‰¹æ¬¡æ¸¬è©¦å ±å‘Š
```json
{
  "llama3.2:latest": [...],
  "deepseek-r1:32b": [...],
  ...
}
```

---

## ğŸ¯ æ¸¬è©¦æ¡ˆä¾‹

### 1. æ¨ç†èƒ½åŠ›
**æ¸¬è©¦ï¼š** é‚è¼¯æ¨ç†å•é¡Œ  
**æç¤ºï¼š** "å¦‚æœ A > B ä¸” B > Cï¼Œé‚£éº¼ A å’Œ C çš„é—œä¿‚æ˜¯ä»€éº¼ï¼Ÿ"  
**è©•ä¼°ï¼š** æº–ç¢ºåº¦ã€æ­¥é©Ÿæ¸…æ™°åº¦ã€ä¸€è‡´æ€§

### 2. ç·¨ç¢¼èƒ½åŠ›
**æ¸¬è©¦ï¼š** ç¨‹å¼ç”Ÿæˆ  
**æç¤ºï¼š** "å¯«ä¸€å€‹è¨ˆç®—æ–æ³¢é‚£å¥‘æ•¸åˆ—çš„å‡½å¼"  
**è©•ä¼°ï¼š** åŠŸèƒ½æ­£ç¢ºæ€§ã€æ•ˆç‡ã€å¯è®€æ€§

### 3. è¦–è¦ºèªè¨€
**æ¸¬è©¦ï¼š** åœ–åƒæè¿°  
**æç¤ºï¼š** "æè¿°é€™å¼µåœ–åƒçš„å…§å®¹"  
**è©•ä¼°ï¼š** æº–ç¢ºåº¦ã€æ·±åº¦ã€å°é½Šåº¦

### 4. é€šç”¨èªè¨€
**æ¸¬è©¦ï¼š** å‰µæ„å¯«ä½œ  
**æç¤ºï¼š** "å¯«ä¸€å€‹é—œæ–¼ AI çš„çŸ­æ–‡"  
**è©•ä¼°ï¼š** æµæš¢åº¦ã€é€£è²«æ€§ã€å‰µæ„

### 5. åµŒå…¥èƒ½åŠ›
**æ¸¬è©¦ï¼š** èªç¾©ç›¸ä¼¼åº¦  
**æç¤ºï¼š** "è¨ˆç®—å…©å€‹å¥å­çš„ç›¸ä¼¼åº¦"  
**è©•ä¼°ï¼š** ç›¸ä¼¼åº¦æº–ç¢ºæ€§ã€èšé¡ã€æª¢ç´¢

---

## ğŸ”§ é…ç½®

### å•Ÿç”¨ Gemini è©•å¯©
ç·¨è¼¯ `config/jade_config.yaml`ï¼š
```yaml
gemini:
  enabled: true
  api_key: "YOUR_GEMINI_API_KEY"
  model: "gemini-2.0-flash-exp"
```

### è‡ªè¨‚æ¸¬è©¦æ¡ˆä¾‹
ç·¨è¼¯ `benchmark.py` ä¸­çš„ `CATEGORIES` å­—å…¸ã€‚

---

## ğŸ“Š èˆ‡ UI æ•´åˆ

### ollama-benchmark-suite UI
1. å•Ÿå‹•å¾Œç«¯ APIï¼ˆå¾…å¯¦ä½œï¼‰
2. UI å‘¼å« `benchmark.py`
3. å³æ™‚é¡¯ç¤ºè©•åˆ†èˆ‡é›·é”åœ–

### è³‡æ–™æµç¨‹
```
UI â†’ benchmark.py â†’ Ollama API â†’ Gemini Judge â†’ UI
```

---

## ğŸ“ é€²éšåŠŸèƒ½

### è‡ªè¨‚è©•å¯©æ¨™æº–
```python
def custom_judge(output, category):
    # å¯¦ä½œè‡ªè¨‚è©•åˆ†é‚è¼¯
    return {'score': 5, 'reasoning': '...'}
```

### åŒ¯å‡ºå ±å‘Š
```bash
# ç”Ÿæˆ Markdown å ±å‘Š
python benchmark.py llama3.2:latest --format markdown

# ç”Ÿæˆ CSV å ±å‘Š
python benchmark.py llama3.2:latest --format csv
```

---

## ğŸ“š åƒè€ƒè³‡æ–™

- [Requirement_Specification.md](../Requirement_Specification.md)
- [LLM Capability Comparison.md](../LLM Capability Comparison.md)
- [Overlay-Benchmarking_Spec_LLM_Performance.md](../Overlay-Benchmarking_Spec_LLM_Performance.md)

---

**å®Œæ•´å¯¦ä½œ Requirement Specificationï¼** âœ…
